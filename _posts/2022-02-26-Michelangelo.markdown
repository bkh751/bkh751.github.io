---
layout: post
title:  "Uber Michelangelo "
categories: mlops
---

원문: https://eng.uber.com/michelangelo-machine-learning-platform/

![https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Featured-Image-768x329.png](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Featured-Image-768x329.png)

우버에서는 ML-as-a-service 플랫폼으로 미켈란젤로를 쓴다. 

미켈란젤로는 팀 내부에서 머신러닝 빌드, 배포, 운영까지 가능한 솔루션이다.  미켈란젤로는 e2e ML workflow 를 수행하도록 설계되어있다: 데이터 관리, 훈련, 측정, 모델 배포 그리고 예측 수행과 예측 모니터링을 한다. 

**미켈란젤로를 개발하게된 동기**

신뢰성있고, 단일화되고 재사용가능한 예측 및 훈련용 데이타 생성 파이프라인 시스템이 없어서 만들게되었다고한다. 미켈란젤로가 없었을때에는, DS 가 쓰는 로컬 머신이 할 수 있는 훈련 량 만큼만 모델 훈련이 가능헀다, 그리고 훈련 실험 결과를 저장하거나, 다른 실험결과를 비교할 수 있기가 쉽지 않았다.  가장 중요한건, 모델을 프로덕션에 배포하는 일관된 방법이 없었다. 대부분의 경우, 엔지니어팀에서 프로젝트에 맞는 서빙 컨테이너를 커스텀하게 만들어서 배포해주는 식이었다. 동시에, [Scully et al](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) 에서 지적한 ML 안티패턴 신호들을 하나씩 보기 시작했다. 

미캘란젤로는 이러한 문제들을 일관된 워크플로우와 툴을 팀에 표준화해서 사용하게 하였다. 

2015 년에는 도전과제가 scalable 한 모델 훈련과 프로덕션에 배포에 컨테이너를 사용하는것이었다. 그리고, 피처 파이프라인을 관리하고 공유할 수 있는 더 나은 시스템을 만드는데 집중하였다. 최근에는, 이러한 관심이 개발자 생산성에 집중이 되었다. 즉, 아이디어로부터 첫 프로덕션 모델까지 만드는것과 빠른 iteration 을 달성하는 것이다.

**예를들면 어떤걸 빌드하고 배포하는가?**

우버 잇츠 유즈케이스가 대표적인데, 여러 비슷한 모델을 회사 내에서 다양한 예측 유즈 케이스를 미켈란젤로 플랫폼을 통해 관리하는 것이다. 

유즈케이스: 배달에 걸리는 시간 (ETD) 예측하기

우버잇츠에서는 배달 시간 예측, 검색랭킹, 검색 자동화, 그리고 식당 랭킹을 위해 여러가지 모델이 돌고있다. 배달 시간 모델의 경우 주문이 발행되기전에 준비하고 배달하는데 걸리는 시간을 예측을한다. 그리고 배달 프로세스의 각 단계마다 다시 한번씩 예측을 수행을 한다.

![http://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image4.png](http://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image4.png)

Fig1. 미켈란젤로를 통해 빌드된 모델로 예측을 하는 모습

우버잇츠 사용자가 주문 요청을하면, 식당에서는 주문을 받아 음식점이 바쁜정도와, 주문의 복잡도를 가지고 음식을 준비하는데 걸리는 시간을 알아야한다. 음식이 준비되어야 할 시간이 가까워지면, 우버 배달 파트너가 음식을 가지러 파견된다. 파견된 배달 파트너는 음식점을 가고, 주차장 찾은뒤, 음식을 찾고, 차로 돌아가고, 주문고객에게 배달을 한다.  이러한 과정을 모두 수행하는데 걸리는 총 시간을 예측하는 것이 모델이 예측하고자하는것이다. 그리고 각 프로세스 별로 배달 시간 예측을 반복한다. 

미켈란젤로 플랫폼에서는 우버잇츠 디에스가 gradient boosted decision tree regression models 을 사용해서 이러한 e2e 시간을 측정한다. 모델을 위한 피처들은 다음과 같은 정보들을 가지고있다. 요청으로부터 오는 정보의 경우 그날의 시각, 배달 장소. 이력으로 부터 알 수 있는 7일간 평균 음식 준비시간,  그리고 거의 실시간으로 계산되는 지난 한시간 동안 음식을 준비하는데 걸리는 평균 시간. 모델들은 우버의 데이타 센터에서 부터 미켈란젤로에 있는 모델 서빙 컨테이너에 배포되고 이러한 배포 과정은 우버잇츠 마이크로서비스의 네트워크 요청에 의해서 수행된다. 이러한 음식 주문에서 부터 음식 준비와 배달까지에 관한 예측 수행들은 우버잇츠의 주문고객에게 표시된다.

**미켈란젤로 시스템 아키텍쳐**

미켈란젤로는 여러 오픈소스와 인하우스에서 빌드된 컴포넌트를 모아 구성되어있다. 주로 사용되는 오픈 소스 컴포넌트의 경우 [HDFS](http://hadoop.apache.org/), [Spark](https://spark.apache.org/), [Samza](http://samza.apache.org/), [Cassandra](http://cassandra.apache.org/), [MLLib](https://spark.apache.org/mllib/), [XGBoost](https://github.com/dmlc/xgboost), and [TensorFlow](https://www.tensorflow.org/) 이다. 
. 우버는 주로 성숙한 오픈소스를 쓰려고 하고있고, 포크하여 커스터마이즈 한뒤 기여하는 것을 선호한다. 가끔씩 오픈소스를 쓰는것이 사용사례에 맞지 않는다면 직접 시스템을 만들기도한다.

미켈란젤로는 우버의 데이타와 컴퓨트 인프라상에 빌드 된다, 그리고 모든 우버의 트랜잭션 및 로그 데이타를 제공하는 데이타 레이크가 된다. 또한 카프카 브로커의 역할도하는데, 서비스로부터 발생하는 로그 메시지를 집합(aggregate)한다.  Samza streaming , Cassandra cluster, 그리고 우버의 인하우스 서비스 프로비져닝과 배포 툴을 포함한다. 

**머신러닝 워크플로**

어떤 문제해결을 할때에 우버에서는 같은 워크플로를 쓰는 경우가 많다. 분류과 회귀를 하거나 시계열 예측을 하는 경우가 그렇다. 워크플로는 보통 implementation-agnostic 한 성질이 있다, 그래서 새로운 알고리즘 타입과 프레임워크를 지원하기위해 확장이 되기가 쉽다. 또한 온라인 과 오프라인 예측 사용사례에서와 같은 서로 다른 배포 방식에도 이러한 확장성이 필요하다.

우버에서는 미켈란젤로를 scalable, reliable, reproducible, easy-to-use, and automated tools 특성을 갖도록 설계하였다. 아래와 같은 6단계 워크플로를 수행한다.

1. 데이터를 관리한다
2. 모델을 훈련한다
3. 모델을 측정한다
4. 모델을 배포한다
5. 예측을 수행한다
6. 예측을 모니터링한다

**데이터 관리**

좋은 피처를 찾는 것은 머신러닝에서 가장힘든 부분이고 우버에서는 데이타 파이프라인을 빌드하고 관리하는것이 완성형 머신러닝 솔루션에 있어서 일반적으로 가장 비용이 많이 드는 부분이다. 

플랫폼은 훈련 및 예측을 위한 피처와 라벨 데이타 셋을 생성하기 위한 데이타 파이프라인을 빌드 할 수 있는 표준화된 툴을 제공해야한다. 이러한 툴은 사내 데이타 레이크나 데이타 웨어하우스, 온라인 데이터 서빙 시스템과 통합이 잘 되어있어야 한다. 파이프라인은 확장가능하고 성능이 우수해야한다, 통합 데이타 플로와 데이타 품질을 모니터링도 마찬가지이다. 또한 온라인과 오프라인 훈련 그리고 예측도 지원해줘야한다. 이상적으로는 피처를 생성해서 팀내에 공유할 수 있는 형태면 좋다 왜냐하면 반복된 작업을 줄이고 데이타 품질을 높이기 때문이다.  이러한 방식은 강한 가드레일이 되어주는데 사용자를 배스트 프랙티스를 사용하도록 가이드 하기 때문이다. (예를들면 똑같은 데이타 생성  프로세스가 훈련 시간과 예측 시간에 사용되도록하는 것을 보장해준다)

데이타 관리 컴포넌트는 온라인과 오프라인 파이프라인으로 나눠진다. 현재, 오프라인 파이프라인은 배치 모델 훈련과 배치 예측 잡들에 데이터를 주입하기 위해 사용된다 그리고 온라인 파이프라인은 온라인 저지연예측에 사용되는 데이터를 주입해준다 ( 그리고 곧 , 온라인 학습 시스템에도 이러한 방식을 적용할 예정이다)

추가로, 데이타 관리에 레이어를 추가헀는데, 팀들간에 공유, 디스커버리, 그리고 여러 머신러닝 문제를 해결하기 위해 선정된 피처 셋들이 선정된 피처스토어이다. 우버는 많은 모델링 문제가 비슷한 피처를 쓴다는 것을 발견했고, 이러한 피처들은 엄청난 가치를 발휘할때가 팀들간에 공유가 되어 각 프로젝트에 적용될때이다. 

![http://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image5.png](http://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/image5.png)

Fig2. 데이타 준비 파이프라인이 피처스토테이블과 훈련 데이타 저장소에 데이타를 밀어 넣고있다. 

**오프라인 모델 (훈련 모델)**

우버의 트랙잭션 및 로그 데이타의 경우 HDFS 데이타 레이크로 흘러들어가고 스파크와 하이브 SQL 연산 잡으로 쉽게 접근이 가능하다. 우버는 컨테이너와 스캐쥴링을 통해 잡들을 돌려 피처들을 만들어 프로젝트에 들어가게끔 해주거나, 피처스토어로 발행이 되게끔해준다  그리고 팀간에 공유가 되게한다. 이러한 배치 잡들이 스캐쥴러나 트리거로 돌고 이러한 잡들이 데이타 품질 모니터링 툴과 통합되면 파이프라인에서 빠르게 회귀를 통해 로컬 혹은 업스트림 코드나 데이타 이슈를 감지할 수 있다. 

**온라인 모델 (배포된 모델)**

온라인에 배포된 모델은 HDFS 에 있는 데이타를 접근할 수 없다, 그리고 몇 피처들을 연산할때 우수한 성능으로 수행할 수 있는 우버 뒷단의 서비스에 사용되는 온라인 DB 에 접근하기 어려울 때가 있다 (예를들면 우버잇츠의 주문 서비스에 바로 쿼리해서 평균 음식 주문시간을 특정 식당에서 특정 시간동안에 한해서 계산하기가 어려울 수 있다).

대신, 우버에서는 온라인 모델에서 사용되는 피처들을 미리 연산되게끔한뒤 카산드라에 저장하여 빠른 시간에 읽을 수 있도록 한다. 

이러한 온라인으로 서빙되는 피처를 위해서 두가지 옵션을 제공한다, 배치 precompute 와 near-realtime compute 옵션이다. 

- **Batch precompute :** 대량의 precomputing을 수행하고 historical 피처들을 HDFS 로부터 가져와서 Cassandra 로 집어 넣는것이다.  간단하면서도 효과적이고 historical 피처들에도 잘 동작한다 왜냐하면 피처들이 몇시간 혹은 하루에 겨우 한번 업데이트를 하기 때문이다.  이러한 시스템은 같은 데이타를 보장하고 배치 파이프라인은 측정과 서빙 둘다에 사용된다. 우버잇츠는 이 시스템을 쓸때 예를들면 지난 7일간의 음식 준비 시간에 대한 피처를 저장하기 위해서 쓴다.
- **Near-real-time compute:**  카프카와 연관된 메트릭을 발행하고 삼자 기반 스트리밍 연산 잡을 돌려 피처들을 집합하는 과정을 저지연성으로 달성한다. 이러한 피처들은 카산드라로 직접 저장이 되고 이후의 훈련 잡을 위해 HDFS 로 로그를 보낸다. 배치 시스템 처럼, 거의 실시간 연산은 똑같은 데이타가 훈련과 서빙에 쓰이는 것을 보장한다. 콜드 스타트를 방지하기 위해, 데이터를 backfill 하기 위한  툴을 제공하고 배치 잡을 로그 이력에서 수행함으로써 훈련 데이타를 생성한다. 우버 잇츠에서는 Near real time 파이프라인을 `식당의 1시간내에 평균 식사 준비 시간` 피처를 위해 쓴다.
    
    

**공유되는 피처스토어**

중앙화된 피처스토어를 통해 엄청난 가치를 얻었는데 어떤 우버팀이든 정규 피처들을 만들고 관리할 수 있다는것이다 그리고 팀 내에서 쓰고 다른 사람들과 공유를 할 수 있다는 것이다. 고수준에서는 , 두가지를 달성하게된다. 

1. 사용자가 공유 피처스토어에 피처를 약간의 메타데이터를 통해 쉽게 추가를 한다. 
2. 한번 피처들이 피처스토어에 있다면, 온라인과 오프라인에서 구독이 굉장히 쉬워진다, 요 과정은 피처의 canonical 이름을 모델 설정에서 참조해서 알 수 있게된다. 이러한 정보와 함게, 시스템은 올바른 HDFS 데이타 셋을 모델 훈련 혹은 배치 예측에 사용하고 올바른 값을 카산드라를 통해 온라인 예측에서 가져올 수 있도록한다. 
    
    

현재 우버는 피처스토어에 10000개에 가까운 피처들을 가지고 머신러닝 프로젝트에 진행에 속력을 더하고있다.  그리고 회사내의 팀들이 새로운 피처를 하나씩 추가하고있다. 피처 스토어의 피처들은 자동적으로 계산되고 매일 업데이트된다. 

미래에는, 우버에서 피처스토어를 검색할 수 있는 자동화된 시스템을 만드는 방법과 예측 문제를 풀기위한 가장 강력한 피처를 식별하는 방법을 찾으려고한다

**피처 선택과 변환에 사용되는 도메인 특정 언어(DSL)**

피처들은 데이타 파이프라인으로 만들어지거나 클라이언트 서비스에서 모델에 적합하지 않은 데이터를 보내줌으로써 생성이된다, 그리고 이러한 피처들은 꼭 필요한 값이 빠져있을때가 있다. 또한, 모델이 제공된 피처의 일부집합만 있어도 괜찮을 때도있다.  어떤 경우에는 하루의 시각 보다 한주의 하루로 타임스탬프를 바꾸는게 게절별 패턴을 캡쳐하기 위해 유리한 경우가있다. 다른 사례의 경우, 피처값들은 정규화 되어야할때가 있다 ( 평균 값을 빼고 표준 편차로 나눈다는 말이다)

이러한 문제를 해결하기 위해, 우버에서는 DSL 을 만들었다. 모델러는 DSL 을 통해 훈련 및 예측 시간에 모델에 보내진 피처를 select, transform, and combine 할 수 있다. DSL 은 Scala  로 만들었다. DSL 로 또 할 수 있는게 고객 팀에서 각자 커스텀 함수를 만들 수 있다. 접근자 함수들과 현재 컨텍스트(데이타 파이프라인인데, 요경우는 오프라인 모델이나 현재 클라이언트 요청에서 사용되는 온라인 모델을 뜻한다)의 피처 값을 가져오거나 피처 스토어로부터 피처를 가져올 수 있다.

DSL이 모델 설정의 일부가 되도록 하는것이 좋고, 훈련시간과 예측 시간에 같은 DSL 이 적용되어야 같은 final set 피처가 생성이 되어 모델로 들어가게된다.

****Train models(모델 훈련)****

****Evaluate models****

****Model accuracy report****

****Decision tree visualization****

****Feature report****

****Deploy models****

****Make predictions****

****Referencing models****

****Scale and latency****

****Monitor predictions****

****Management plane, API, and web UI****
